
# 翻译
## 摘要
软件中的大规模代码支持着丰富多样的功能，同时也包含着潜在的漏洞。模糊测试作为最流行的漏洞检测方法之一，在工业界和学术界都在不断发展，旨在通过覆盖更多的代码来发现更多的漏洞。然而，我们发现即使使用最先进的模糊器，仍然有一些未开发的代码只能使用特定的程序选项组合来触发。由于没有考虑到选项之间的约束(或称为关系)，简单地改变选项可能会产生许多无效的组合。在本文中，我们利用自然语言处理(NLP)从程序文档中自动提取选项描述，并分析选项之间的关系(例如，冲突，依赖关系)，然后过滤掉无效的组合，只留下有效的组合进行模糊测试。我们实现了一个名为CarpetFuzz的工具，并评估了它的性能。结果表明，CarpetFuzz能够准确地从文档中提取关系，准确率为96.10%，召回率为88.85%。基于这些关系，CarpetFuzz减少了67.91%要测试的选项组合。它帮助AFL多发现45.97%的路径，这是其他模糊器无法发现的。在分析了20个流行的开源程序后，CarpetFuzz发现了57个漏洞，其中包括43个未公开的漏洞。我们还成功获取了30个漏洞的CVE id。

## 1.引言
随着软件复杂性的增加，软件中的代码规模也迅速增加。例如，根据OpenHub的分析报告[36,37]，目前流行的软件Apache HTTP Server和MySQL的代码行数分别达到160万行和290万行。大规模的代码支持了软件丰富多样的功能，满足了用户的各种需求。但是，它也扩大了攻击面，增加了发现潜在漏洞的难度，带来了更高的安全风险和防御成本。

覆盖率引导的模糊测试是最成功的漏洞发现技术之一[69]，它不断改变输入以增加代码覆盖率，从而触发软件中潜在的安全违规(例如，写访问违规)。以往的研究大多集中在模糊过程中的优化策略上，如种子选择[20,41]、种子调度[3,4,40,54,61,67]、突变[8,32]和反馈策略[1,6,15,16,30,33,44]。这些改进大大增强了fuzzers发现漏洞的能力。截至2022年1月，仅谷歌的连续模糊服务OSS-Fuzz就发现了36000多个漏洞[19]。然而，尽管最新的fuzzers使用不同的策略来选择各种种子和突变输入，并且已经具有强大的程序探索能力，但仍有一些代码未被探索。

主要原因是这些最新的模糊器没有使用一些特定的命令行选项来模糊程序。命令行选项(或简单的选项)告诉程序要修改哪个操作。一些选项对应于不同的程序分支，这意味着某些代码只能通过指定某些选项而不是更改输入文件来访问。然而，在之前暴露的漏洞中，只指定了一小部分选项。例如，从2014年到2020年，Libtiff的103个cve只指定了20种不同的选项，占总选项的9.8%，这意味着许多与选项相关的代码可能仍未被探索。由于组合的数量可能很大，因此遍历它们是不现实的。例如，流行的图像处理程序ImageMagick有242种不同的选项[23]，有7.1×1072可能的组合。

一些研究人员[5,9,29,45,55,66]试图通过改变选项组合来解决这一限制。然而，由于缺乏考虑选项之间的关系，例如冲突(即不能一起使用)和依赖(即必须一起使用)，许多突变组合可能是无效的。例如，使用先前研究的突变算法生成的openssl-rsa组合中只有11%是有效的。本文旨在提取选项之间的关系，但由于以下原因，这是具有挑战性的。

挑战- C1。选项之间的关系通常在文档中以自然语言声明，并且可以以完全不同的方式声明，这大大增加了识别难度。例如，-a和-b选项之间的冲突可以通过几种方式声明，如“-a不能与-b一起使用”，“-a与-b互斥”，以及“只能给出这些选项中的一个”。像模板匹配这样的简单方法不能很好地解决这个问题。此外，有些关系是隐式声明的，只能通过比较多个句子来识别。例如，tiffcp文档将-B和-L选项描述为“强制以大端字节顺序写入输出”和“强制以小端字节顺序写入输出”。虽然没有明确声明，但可以通过比较这两个句子来推断-B和-L之间的冲突，这两个句子描述了两种截然相反的行为。识别这些关系的一种准确而直接的方法是人工检查，但这是一种劳动密集型的方法，对于大规模的识别是不现实的。如何从文档中自动找出选项之间的关系变得非常必要。

挑战- C2。在从文档中确定了自然语言形式的关系之后，仍然很难自动提取具体的关系(例如，冲突或依赖)。首先，自动定位关系的相关选项是一项挑战。例如，“-f或-b必须与-C一起使用，而-C不能与-f或-d一起使用”这句话声明了-f、-b和-C选项之间的依赖关系，以及-C、-f和-d选项之间的冲突。如果没有对语法结构的准确分析，就不能自动确定这些关系的相关选项。其次，如前所述，选项之间的关系可以用完全不同的方式声明。因此，不能使用关键字匹配这样的简单方法来确定自动声明的关系类型。

在本文中，我们解决了上述挑战，并提出了CarpetFuzz，一个基于NLP的模糊辅助工具，用于提取程序选项约束。CarpetFuzz的基本思想是使用自然语言处理(NLP)从文档中每个选项的描述中识别和提取程序选项之间的关系(例如，冲突或依赖关系)，并过滤掉无效的组合，以减少需要模糊的选项组合。给定一个程序的文档，CarpetFuzz首先通过解析options部分提取它的所有选项和相应的描述。然后CarpetFuzz使用机器学习模型来确定是否在描述中声明了关系。由于这些句子在文档中所占的比例很小(例如，在tiffcp文档中占3.4%)，我们使用基于熵的不确定性抽样[11]，一种有效的主动学习方法，来减少人类在标记训练数据方面的工作量。为了识别由多个句子隐式声明的关系，CarpetFuzz总结了隐式声明的一系列特征，并利用NLP找到满足这些特征的所有句子对。在确定程序中选项之间的关系之后，CarpetFuzz利用混合向前和向后遍历方法从依赖关系树(从依赖关系解析中获得)中查找与关系相关的节点。此外，CarpetFuzz基于语言学，利用基于极性的有限状态机来确定具体关系。最后，CarpetFuzz过滤掉不满足这些关系的组合，以减少用于模糊处理的组合数量。

## 3.设计
在本节中，我们描述了CarpetFuzz的设计，这是一个基于nlp的模糊测试辅助工具，用于提取程序选项约束。核心思想是使用NLP从文档中每个选项的描述中识别和提取程序选项之间的关系(例如，冲突或依赖关系)，并过滤掉无效的组合，以减少需要模糊化的选项组合。我们首先介绍整个设计的总体概述，然后展示每个组件的工作原理。

### 3.1 概述
图2显示了CarpetFuzz的概述。给定目标程序的文档，CarpetFuzz首先通过解析options部分提取其所有选项和相应的描述，并使用NLP工具将这些描述分成句子(步骤1)。然后CarpetFuzz识别这些选项之间包含关系的句子(称为r -sentence 2)(步骤2)。具体而言，通过主动学习算法，CarpetFuzz从Linux手册页构建数据集，并训练机器学习模型来识别显式声明的关系。为了找到隐式声明的关系，CarpetFuzz将NLP解析技术(依赖项解析和群体解析)与我们的启发式规则结合起来。在识别r -句之后，CarpetFuzz通过依赖解析构建这些r -句的依赖树，并从选项所在的节点遍历依赖树以提取具体的关系和对象(步骤3)。通过提取的关系，CarpetFuzz构建有效的选项组合并按覆盖优先级排序(步骤4)。最后，CarpetFuzz将这些优先级的有效选项组合传递给模糊器。

![](images/Pasted%20image%2020230704170937.png)

### 3.2 显式声明的关系标识
通过对大量文档的分析，我们发现显式声明的选项之间的关系主要可以分为五类，分别是冲突、依赖、暗示、相似和取代(附录a)。选项之间的冲突表示这些选项不能一起使用，选项之间的依赖表示这些选项必须一起使用。含义表示一个选项的功能包含另一个选项。相似性和取代性表示选项的功能分别大致相同和可替换。所有这三种关系都表明多个选项的功能存在重叠。虽然选项与这三种关系的组合可能不会导致异常，但它会使一些选项被覆盖。对这些选项的组合进行模糊处理可能会产生与对每个选项进行模糊处理相同的效果，并且可能对发现新路径毫无用处。为了避免这种无用的组合，减少搜索空间，本文将这三种关系视为冲突。

我们从互联网上收集大量文档，并提取所有选项描述中的句子作为未标记数据集。为了降低标注成本，我们使用主动学习算法对未标注数据集中的部分样本进行手动标注，并将其添加到标注数据集中。具体来说，我们首先阅读一小部分文档，并手动收集r句中的多个关键字(大约20个)(例如，“combine with”，“imply”，“like”，“ignore”)，这是一个小的一次性工作(大约5分钟)。请注意，虽然这些关键词来自少数文档，但它们也适用于其他文档，并且可以通过主动学习中的数据标记系统地增强。然后我们从包含这些关键词的句子中抽取一个子集进行人工标注，这就是我们模型的初始训练数据集。具有以上五种关系的句子被标记为积极的，其他的句子被标记为消极的。通常，数百个标记数据足以训练初始模型，而与数据集的大小无关。我们利用word2vec模型[42]将单词映射为向量作为输入特征，因为它简单且成本低。我们还评估了更高级的模型(例如BERT[13])，并获得了类似的性能。在主动学习算法的每次迭代中，使用机器学习模型对未标记数据集中的所有样本进行预测，并根据基于熵的不确定性采样算法选择样本进行人工标记[11];

![](images/Pasted%20image%2020230704222248.png)

其中ei为第i个未标记样本的熵，P(y1|xi)表示xi属于第1类(是r句)的预测概率，P(y0|xi)表示xi属于第0类(不是r句)的预测概率。当模型预测样本时，更高的熵表示更高的不确定性。因此，标记这些样本有助于更有效地更新模型。将K个具有最高熵的样本手动标记并添加到训练集中，并使用更新的训练集重新训练模型(附录B)。经过T次迭代后，最终模型将用于显式声明的关系识别。特别是在主动学习过程中，我们手工标注了1381个句子(557个肯定句和824个否定句)，仅占所有未标注句子的0.46%。请注意，数据标记是一次性的工作(仅在训练过程中执行，大约5个小时)，以后的测试不需要人工操作。我们从剩余的未标记数据集中随机抽取1000个数据进行评估，最终模型的准确率、假阳性率和召回率分别为92.90%、11.49%和98.42%。

### 3.3隐式声明的关系标识
正如在引言中提到的，识别隐式声明的关系是一项挑战。这些关系涉及多个选项，这些选项的行为不同但相关，只有在找到关联时才能识别。在分析了大量程序的文档之后，我们只发现了隐式声明的冲突(尚未发现隐式声明的依赖关系)。在本文中，我们只讨论隐式声明冲突的识别。我们发现这些句子隐含地声明了冲突(即:隐含r句)在不同的选项之间通常有相同的对象和相同的/反义词动词，这意味着这些选项在相同的对象上做相同(或相反)的事情。它们的语法结构通常满足平行结构(即，在几个部分中重复相同的语法形式)，这可能是因为文档的作者为了方便而复制了每个冲突选项的描述。例如，-B和-L选项的描述是“强制以大端字节顺序写入输出”和“强制以小端字节顺序写入输出”。由于这两个句子具有相同的谓词(即力)、对象(即输出)和语法结构(解析树)，因此我们可以确定它们是隐式r句。

为了确定几个句子是否为隐式r句子，我们需要提取对象、谓词及其描述的解析树。图3显示了提取这些特征的过程。我们首先对描述进行预处理(第1步)，提取每个描述的第一个句子进行分析，因为这个句子通常是介绍选项功能的主题句。我们发现选项的一些主题句可能没有主语(以动词开头)，导致NLP解析器出现错误，例如错误地将动词“force”判断为名词。因此，对于以动词开头的句子，我们恢复其主语(即it)并修改动词的人称以避免解析错误。例如，tiffcp中-B选项的描述“强制以大端字节顺序写入输出”将被修改为“强制以大端字节顺序写入输出”。

![](images/Pasted%20image%2020230704222832.png)

预处理后，对句子进行依赖句法分析，找到谓语和直接宾语。具体来说，我们使用NLP工具来标记每个单词的依赖标签，并找到带有“dobj”(即直接对象)和“ROOT”(即谓词)标签的单词。为了确定这两个句子是否具有平行结构，我们使用群体解析来构建它们的解析树并删除它们的叶节点，因为叶节点代表特定的单词而不是语法结构。如果它们的长度相同，当它们剩下的树相同时，我们判断它们是平行的。如果它们的长度不同，我们首先从它的最后一个节点遍历较短的树，找到最近的分支节点，然后删除该分支节点及其所有子节点。如果剩下的树是长树的子树，我们认为这两棵树是平行结构。最后，当几个句子具有相同的对象、相同或相互匿名的谓词和具有平行结构的解析树时，它们被认为是隐式r句。

此外，在某些文档中，多个选项一起写在同一位置，这是另一种隐式声明冲突。例如，openssl-ec中的-des、-des3和-idea选项一起写成“-des|-des3|-idea”，如图4所示。然而，写在一起的选项不一定是冲突的——它们可能是同一选项的别名。例如，尽管-s和-silent选项写在一起为“-s， -silent”，但它们并不冲突，而是相同的选项。我们可以通过检查主题句的主语来判断多个选项共享的主题句是否为隐式r句。当主语是复数时(例如，“they”或“these options”)，这意味着这个句子是一个隐含的r句。

![](images/Pasted%20image%2020230704222755.png)

总的来说，我们从20个流行的节目文档中发现了218个隐式声明的冲突对。精密度为95.87%，召回率为90.09%。

### 3.4 关系提取
从文档中找到r -sentence后，我们需要从这些句子中提取出具体的关系，包括冲突和依赖关系(如3.2节所述，隐含、相似和取代也被视为冲突)。

提取显式声明的关系。对于显式声明关系的复合句，我们首先使用群体解析将复合句划分为多个子句。如果子句包含选项，我们用自定义符号(例如，option_A)替换它们的名称，以避免负号干扰解析。然后，我们使用依赖解析来获得该子句的解析树。图5显示了基于解析树的显式声明关系的提取过程。首先，我们定位第一个选项出现的位置，并向前遍历解析树，以查看是否有任何其他选项与第一个选项(即“conj”标记)有共同依赖关系。由于r句中可能包含其他程序的选项，我们在分析之前先检查所定位的选项是否属于目标程序。我们将具有共同依赖关系的选项视为单个选项，并确认连词(即“cc”标签)。对于没有共同依赖的选项，我们分别为它们执行关系提取过程。其次，我们从选项的位置向后遍历解析树，以找到与该选项相关的动词或形容词(即“pobj”和“prep”标记)。然后，我们将这个单词与我们的关键字(从许多文档中收集并基于同义词进行扩充)进行比较，以确认它是否是关键字。如果不是，我们搜索它的所有同义词，并将它们与关键字进行比较。第三，我们从动词的位置向后遍历解析树，找到与该动词相关的否定和情态(即“aux”标记)，以确定具体关系。

![](images/Pasted%20image%2020230704225131.png)

如上所述，可以用完全不同的方式声明关系。首先，相同的关系可以由不同的关键字声明。另一方面，同一关键字所描述的关系可能在不同的上下文中有所不同。例如，关键字“use”分别描述了“必须使用”、“必须使用”和“必须不使用”中的依赖性、中立性(无关系)和冲突。根据语言学[25]，冲突和依赖可以被视为一对极性相反的项目，而中立性是这两个极性之间的中介(即既不冲突也不依赖)。这三个词可以根据特定的句子成分进行过渡，如关键词、道义情态动词(即表示义务和许可的情态动词，如“must”、“should”和“have to”)和否定。

我们使用两个有限状态机(fsm)来描述状态转换过程，如图6所示。FSM的选择与基于语义的关键字分类有关，包括冲突关键字和依赖关键字(附录C)。每个FSM包含三种状态SD、SN和SC(即依赖、中立和冲突)，以及两种可能的初始状态。FSM的初始状态是关键字(附录C)的默认关系，没有道义情态和否定。例如，由于“be used”表示中立性，所以关键字“use”的默认关系是中立性。在确定了初始状态之后，我们可以根据句子中的道义情态和否定来推断最终状态，这就是所表达的关系。需要注意的是，根据语言学[22]，道义情态动词在否定下有作用，这意味着只有当两者都存在时，否定才会起作用3。我们以“-A不能与-B和-C一起使用”这句话为例。因为关键字“use”是一个依赖关键字，所以选择了底层FSM，初始状态是中立的。由于句中既有道义情态又有否定，所以只有否定才会起作用。从FSM的依赖关键字，状态将从中立过渡到冲突。

![](images/Pasted%20image%2020230704225155.png)

提取隐式声明的关系。对于隐式r句子，它们被确定为冲突声明，我们只需要将这些句子映射到相应的选项，这已经在图2的步骤1中完成了。例如，根据3.3节的方法，我们可以知道“Force output to be written with Big-Endian byte order”和“Force output to be written with Little-Endian byte order”这两个句子是隐式r句。根据选项和句子的对应关系，我们可以知道这两个句子分别属于-B和-L选项。最后，我们提取-B和-L选项之间的冲突关系。

最后，利用我们的关系提取方法，我们成功地从20个热门节目文档中提取了282个关系，准确率和召回率分别为96.10%和88.85%。

### 3.5 组合和优先排序
基于提取的选项之间的关系，我们可以过滤掉所有无效的选项组合。具体来说，我们将所有长度为n的选项组合在一起(0≤n≤k，其中k是选项的个数)，并根据提取的关系对生成的组合执行有效性检查。只有当一个组合满足所有依赖关系并且没有冲突时，它才被认为是有效的。对于可以有值的选项，我们手动从文档中为每个选项收集合理的值，并随机为每个组合中的每个选项选择一个值。

尽管无效的组合被过滤掉了，它们占了全部组合的大部分(例如，opensslrsa中的99.84%)，但剩下的有效组合的数量可能仍然很大(例如，数百万)，并且测试所有这些组合是不切实际的，这将需要大量的计算资源。在本文中，我们利用N-wise测试[57]来进一步修剪需要测试的组合。该测试是组合交互测试的一种有效方法，通过关注N个因素交互导致的缺陷，大大减少了需要测试的组合。研究表明，几乎所有的缺陷都是由不超过6个因素的相互作用造成的[27]。

所以我们使用6-wise (N = 6)测试来修剪有效的选项组合。在修剪组合后，我们根据其在同一种子文件上的干燥运行中的覆盖率对每个组合进行优先排序。具体来说，具有更高覆盖率的组合将具有更高的优先级。我们将这种优先级划分技术用于两个主要考虑因素。首先，在演练中使用覆盖率较高的组合进行模糊测试更有可能在模糊测试过程中发现新的路径。其次，对于一些在前面步骤中没有识别的无效组合，我们的优先级技术可以降低它们的优先级，减少它们被测试的机会。

用组合模糊测试。最后，我们用所有优先修剪的选项组合模糊每个程序。具体地说，我们对目标程序进行检测，使其能够从文件中读取选项，并让模糊器动态修改文件，以切换正在使用的组合。在模糊测试开始时，我们使用所有给定的组合来改变种子文件，并在生成新的测试用例时记录相应的组合。然后我们使用相应的组合来改变队列中的每个测试用例。

## 4.实现
本节介绍了CarpetFuzz原型在我们的研究中的实现，包括数据集收集、模型训练、NLP分析、优先级排序和模糊测试。

数据集集合。我们通过从Debian manpages Project[12]中抓取所有命令行程序的手册页(37,672)来收集训练数据集，该项目是Debian中包含的所有手册页的完整存储库。请注意，文档以三种形式存在:手册页、在线文档和帮助命令。考虑到在线文档通常是从手册页生成的，并且由于空间限制，帮助命令的输出通常很简短，并且没有我们需要的信息，因此我们选择了要解析的手册页。在抓取这些手册页之后，我们基于GNU roff语言(即Groff)[56]提取了选项部分的内容，并将每个选项映射到其描述。具体来说，我们删除了Groff中定义的所有格式标签，并通过段落分隔符(“。“和”。IP”标签)。我们将多个选项之间的内容视为它们的描述。然后我们使用spaCy[47]进行句子切分。最后，我们收集了302,875个与选项相关的句子(重复数据删除后为228,827个)。

模型的训练。我们使用Gensim库中的Word2Vec模型[42]将单词映射为向量，使用以下参数进行训练:size = 300, window = 5，以及其他默认设置。由于选项的描述可能包含其自身，因此我们在预处理过程中将句子中的选项名称转换为option_itself和option_other。我们使用XGBoost对与选项相关的句子进行分类，因为我们实验发现XGBoost[7]比其他机器学习模型(例如SVM[10]和RF[21])具有更好的性能。我们使用默认的超参数在初始数据集(297个积极句子和139个否定句子)上训练初始模型。在主动学习过程的每次迭代中，我们选择20 (K = 20)个熵最高的句子进行手动标注，并使用网格搜索中的最优超参数重新训练我们的模型[28]。我们在70次连续迭代后停止训练(即，T = 70)。最终模型的超参数为:max_depth = 6, n_estimators = 200, colsample_bytree = 0.8, subsample = 0.8, learning_rate = 0.1等默认设置。

NLP分析。我们使用NLTK[39]输出单词的所有词性，使用lemminreflect[2]在添加主语后将动词转换为第三人称单数。我们利用空间空间进行句子分割，提取第一个句子，并利用依赖解析标记每个单词的依赖标签。对于选区解析，我们使用AllenNLP库[24]构建解析树，并基于“SBAR”标签提取子句。在分析中，我们发现不同的数字导致不同的依赖解析结果，这是NLP模型的一个缺陷。作为修复，我们删除了所有非选项号。优先级和模糊化。我们使用PICT工具[34]来实现6-wise测试，并根据提取的关系自动生成模型文件，以指定组合的限制。我们使用afl-showmap[62]作为排序标准来计算干运行的边缘覆盖信息，并使用LLVM pass[53]来检测目标程序。

## 5.评估
本节描述了我们对CarpetFuzz的评估，包括它的端到端操作和单个组件的有效性。

真实世界数据集。在本次评估中，我们评估了CarpetFuzz在20个流行的现实世界程序的最新版本上的有效性(附录D)。这些程序处理11种不同类型的输入文件，包括图像(TIFF和JPG)、证书(PEM)、文本(MD和JSON)、流量包(PCAP)、可执行文件(ELF)、存档(LRZ)、音频(OGG和SPX)和文档(PDF)。我们选择这些程序是因为它们是广泛使用的程序，有十多个选项，并且持续维护。我们从编译目录(例如，“share/man/man1/”)中收集了他们最新的手册页，并手动提取了所有r -句子和关系以供评估。每个程序的选项数量和关系见附录D。

实验设置。我们使用CarpetFuzz来增强AFL[63]，并将其与原始AFL进行比较，以演示CarpetFuzz如何帮助它。为了突出CarpetFuzz的效果，我们还选择了最新版本的AFLfast [4]， MOPT-AFL[32]和AFLplusplus[14]进行比较，这是基于AFL的最流行的改进fuzzers。每个fuzzer都从AFL目录、测试目录(用于PEM和MD格式)或在线语料库[35](用于OGG和SPX格式)收集相同的单个种子文件开始。我们在48个CPU小时内连续模糊我们的测试程序，并重复实验5次，以避免在[26]中提到的模糊器固有不确定性的影响。我们的实验是在一台带有24个CPU核和188GB RAM的Intel Xeon Platinum 8268机器上进行的，它运行的是Ubuntu 20.04.5 LTS。

研究的问题。在以下章节中，我们旨在回答以下研究问题:
RQ1。CarpetFuzz的性能如何?
RQ2。关系识别的准确性是多少?
RQ3。关系提取的准确性如何?
RQ4。CarpetFuzz的优先级划分技术的有效性如何?
RQ5。CarpetFuzz的模糊性能与最先进的技术相比如何?
RQ6。CarpetFuzz能发现现实世界的漏洞吗?

### 5.1 CarpetFuzz (RQ1)性能
在本实验中，我们旨在评估CarpetFuzz的性能。为了突出CarpetFuzz对AFL性能的改善，我们将评估指标定义为CarpetFuzz仅覆盖的边缘数量。

从20个程序的手册页中，CarpetFuzz提取了282个关系，平均过滤掉了67.91%的选项组合(附录E)。根据这些关系，CarpetFuzz将20个程序中需要测试的选项组合减少了25.00%，达到99.85%。可以看出，对于选项之间关系复杂的程序(如openssl-rsa和eu- elfclassified)， CarpetFuzz可以大大减少需要测试的组合数量。我们手动标记了这些程序中的关系，以评估过滤掉无效选项组合的过程。准确率和召回率分别为68.46% ~ 100%和70.00% ~ 100%，平均值分别为98.01%和94.19%，表明CarpetFuzz能够准确识别和过滤掉无效的期权组合。请注意，pdftotext和tiffcp(第5.3节)中只有少量误判，但由于总关系数量少，在提取的所有关系中占很大比例，这导致精度/召回率较低(68.48%/70.00%)。

在过滤无效的选项组合后，我们使用第3.5节中提到的6-wise测试来进一步修剪剩余的组合。为了评估修剪是否会导致覆盖范围的损失，我们对每个程序随机抽样了100,000个有效组合进行比较(附录F)。结果表明，与随机抽样相比，我们的剪枝技术可以减少更多的组合(98.91%)，而只丢失少量的边(2.54%)。

然后，我们使用AFL、AFLfast、mpt -AFL和afl++来模糊每个没有选项的程序(或使用最少的选项使其工作)，并使用CarpetFuzz按照优先级顺序对修剪后的选项组合进行模糊。每个fuzzer的代码覆盖率的增长曲线在48小时内收敛，表示这些fuzzers的覆盖率最终趋于稳定，使用48小时的覆盖率基本上代表了这些fuzzers每次运行的覆盖能力。

我们使用AFL可以达到的边缘作为基线来评估CarpetFuzz的性能。由于固有的不确定性，同一模糊器每次运行的覆盖范围可能相差很大，因此单个覆盖范围不能代表该模糊器的覆盖能力。相反，我们取五次运行的覆盖范围的并集来表示模糊器能够到达的边缘。我们定义了测试模糊器n的唯一边的数量(基线无法到达的边)和唯一边的比率r为

![](images/Pasted%20image%2020230704225639.png)

其中Ef表示五次运行中模糊器边缘覆盖的并集，Eb表示五次运行中基线边缘覆盖的并集。然后，我们计算每个fuzzer的唯一边的数量和比例，如表1的前14列所示。以AFL为基准，AFLfast发现的唯一边最少，20个方案的唯一边占比平均为1.31%，这可能是因为AFLfast主要改进了AFL的种子调度策略，加快了覆盖曲线的收敛速度。MOPT和afl++比AFLfast发现了更多的独特边缘，两种模糊器的独特边缘比例分别为4.47%和5.39%。我们认为MOPT和afl++比AFLfast表现得更好，可能是因为它们改善了AFL的突变策略。然而，即使没有优化任何AFL策略，CarpetFuzz也能找到最独特的边，平均独特率为47.23%。在所有这20个程序中，CarpetFuzz的比率高于其他fuzzers，最高为336.20% (lrzip)，至少是其他fuzzers的293.33倍(afl++)。结果表明，对于某些程序，如eu- el分类和jpegom，通过改进模糊化策略可能会发现很少的唯一边缘，但通过指定某些有效的选项组合可以缓解这种情况。

我们还对前四个fuzzers的边进行并集，以调查carpetfuzzers有多少条边不能被其他fuzzers发现，如表1的最后三列所示。结果表明，CarpetFuzz的独特边缘平均有94.59%没有被其他fuzzers发现，CarpetFuzz可以帮助AFL平均多发现45.97%其他fuzzers无法发现的边缘。

### 5.2 关系识别的准确性(RQ2)


## 7.结论
我们设计并实现了CarpetFuzz，这是一种基于nlp的模糊辅助技术，用于提取程序选项约束。CarpetFuzz受益于主动学习、机器学习和自然语言处理技术，可以准确地从文档中提取选项之间的关系，并过滤掉67.91%的选项组合。通过修剪有效组合，CarpetFuzz帮助AFL在20个流行程序中发现了45.97%的路径，而其他fuzzers无法发现，并发现了57个独特的崩溃，其中30个被分配了CVE id。此外，CarpetFuzz在前一项研究的基准上发现了94次独特的崩溃，是前一项研究的1.71倍。

# 复现
```
sudo docker build -t carpetfuzz:latest . --network host --build-arg HTTP_PROXY=http://192.168.65.1:7890 --build-arg HTTPS_PROXY=http://192.168.65.1:7890
```


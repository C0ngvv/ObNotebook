## 1.覆盖率检测
向目标程序注入以下工具来捕获分支(边缘)覆盖率和分支命中计数
- 一条边表示为当前基本块(分配了一个随机常数)与前一个基本块(即元组 (prev_location, cur_location))之间的 XOR
- 覆盖信息存储在一个紧凑共享的64KB的哈希表中，称为跟踪位图(bitmap)
- 当访问一条边时，通过增加与该特定边的哈希相对应的位图中的值来记录命中

```
cur_location = <COMPILE_TIME_RANDOM>; # cur_location 值是随机生成的，以简化链接复杂项目的过程并保持 XOR 输出均匀分布。
shared_mem[cur_location ^ prev_location]++; # 由调用者传递给检测的二进制文件。
prev_location = cur_location >> 1; # 保持元组的方向性 以区分 A^B 和 B^A ,并保持紧密循环的标识,区分A^A,B^B
```

## 2.新路径检测
### 1.检测新元组
### 2.桶（元组命中数）
```
1, 2, 3, 4-7, 8-15, 16-31, 32-127, 128+
```

buckets 的数量是一种实现工具(implementation artifact)，它可以将由8-bit计数器到8-position位图的映射，前者由插桩产生，后者由 AFL 运行时路径已出现的元组数来计数。

在单个桶范围内的变化会被忽略； 从一个桶到另一个桶的转换被标记为程序控制流中有趣的变化。也会指导下一阶段的进化过程 evolutionary process

### 3.输入队列进化
产生了新的程序状态转换的变异测试用例会被添加到输入队列中，并用作新一轮次 fuzzing 的起点。它们作为已有测试用例的补充，但并不替换掉已有测试用例。

### 4. 精简语料库(Culling the corpus)
在进行fuzzing测试时，后期生成的某些测试用例可能会具有比其祖先提供的覆盖范围更为严格的边缘覆盖。换句话说，这种方法可以帮助测试人员发现更多的程序漏洞，因为后期生成的测试用例具有更高的覆盖率。

为了优化fuzzing测试，AFL定期使用快速算法重新评估队列：选择一小部分测试用例，这些测试用例仍然覆盖到目前为止见到的每个元组，并且它们的特征使它们对工具特别有利。

在这个过程中，AFL会生成一个“喜爱”的输入文件集合，这些文件集合通常比起始数据集小5-10倍。非“喜爱”的输入文件不会被丢弃，但当它们在队列中遇到时，会以不同的概率被跳过：

- 如果队列中有新的、尚未进行fuzzing测试的“喜爱”文件，则99%的非“喜爱”文件将被跳过，以便处理“喜爱”文件。
- 如果队列中没有新的“喜爱”文件：
    - 如果当前的非“喜爱”文件已经进行过fuzzing测试，则95%的时间会跳过该文件。
    - 如果该文件还没有进行任何fuzzing测试，则跳过的概率下降到75%。

### 5.修剪输入文件
文件大小对fuzzing测试的性能有重大影响，因为大文件会使目标程序执行变慢，并降低变异操作所触及的重要格式控制结构的可能性，从而降低测试的效率。

如果用户提供的初始输入文件(语料)质量较低，那么可能会导致AFL生成的测试用例也质量较低。而对于生成的文件大小不断增加的情况，这是因为某些变异策略会在每次迭代中添加更多的数据，从而导致生成的文件大小不断增加。

为了解决这个问题，AFL提供了一些性能优化技巧，如修剪输入文件和控制文件大小。
- 修剪输入文件是指删除不必要的部分，以减小文件大小；
- 控制文件大小是指限制每个测试用例的最大大小，以防止文件大小无限制地增加。



## 参考

[【译】AFL白皮书 | 郁涛丶's Blog (ghostasky.github.io)](https://ghostasky.github.io/2023/05/16/2023-5AFLWritePaper/)

[AFL(american fuzzy lop)学习二_afl 中粧点边计算-CSDN博客](https://blog.csdn.net/sizaif/article/details/124268192)

